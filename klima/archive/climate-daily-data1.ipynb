{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ro=['5765358043206','9812808043220','9576658043223','1699958043227','7225068043228','265208043229']\n",
    "hu=['8073718043234','2087988043232','6247548043235']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5765358043206\n",
      "9812808043220\n",
      "9576658043223\n",
      "1699958043227\n",
      "7225068043228\n",
      "265208043229\n",
      "8073718043234\n",
      "2087988043232\n",
      "6247548043235\n"
     ]
    }
   ],
   "source": [
    "stations=[]\n",
    "for i in ro+hu:\n",
    "    stations.append(pd.read_csv(i+'stn+.txt',delimiter= '+',skiprows=2,header=None))\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "station=pd.concat(stations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "station=station.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "station[2]=station[2].str.strip()\n",
    "station[3]=station[3].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5765358043206\n",
      "9812808043220\n",
      "9576658043223\n",
      "1699958043227\n",
      "7225068043228\n",
      "265208043229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\plotly\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3058: DtypeWarning:\n",
      "\n",
      "Columns (4,11,12,21,22,23,25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8073718043234\n",
      "2087988043232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\plotly\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3058: DtypeWarning:\n",
      "\n",
      "Columns (4,11,12,20,21,22,23,24,25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6247548043235\n"
     ]
    }
   ],
   "source": [
    "dfs=[]\n",
    "for i in ro+hu:\n",
    "    df=pd.read_csv(i+'dat.txt',delimiter= '\\s+')\n",
    "    df=df.replace({'******':np.nan,'*****':np.nan,'****':np.nan,'***':np.nan,'**':np.nan,'*':np.nan})\n",
    "    df['time']=pd.to_datetime(df['YR--MODAHRMN'],format='%Y%m%d%H%M')\n",
    "    df=df[['time','USAF','SPD','TEMP','PCP06','SD','MW','AW','W']]\n",
    "    df['TEMP']=(pd.to_numeric(df['TEMP'], errors='coerce')-32)*5/9\n",
    "    df['SPD']=pd.to_numeric(df['SPD'], errors='coerce')*1.61\n",
    "    df['PCP06']=pd.to_numeric(df['PCP06'], errors='coerce')*25.4\n",
    "    df['SD']=pd.to_numeric(df['SD'], errors='coerce')*25.4\n",
    "    dfs.append(df)\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs=pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs=dfs.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1974, 1978, 1979, 1980, 1981, 1982, 1983, 1984, 1985, 1986, 1987,\n",
       "       1988, 1989, 1990, 1991, 1992, 1993, 1994, 1995, 1997, 1998, 1999,\n",
       "       2000, 2001, 2002, 2003, 2004, 2009, 2012, 2014, 2015, 2016, 2017,\n",
       "       2018, 2019], dtype=int64)"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs[dfs['USAF']==154550].year.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs.to_csv('data/all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs=pd.read_csv('data/all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs['time']=pd.to_datetime(dfs['time'])\n",
    "dfs['year']=dfs['time'].dt.year\n",
    "dfs['month']=dfs['time'].dt.month\n",
    "dfs['day']=dfs['time'].dt.day\n",
    "dfs['hour']=dfs['time'].dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=dfs.groupby(['USAF','year','month','day','hour'])[['TEMP','SPD','SD','PCP06']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avg=df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avg.columns=['temp_avg','spd_avg','snow_avg','rain_avg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avg=np.round(df_avg,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keep only months with at least 6 days to avoid anomalies (20%)\n",
    "filt=df_avg.reset_index().groupby(['USAF','year','month'])[['day']].nunique()\n",
    "filt2=filt[filt>5].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keep only years with at least 3 months to avoid anomalies (20%)\n",
    "filt3=filt2.reset_index().groupby(['USAF','year'])[['month']].nunique()\n",
    "filt4=filt3[filt3>3].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avg2=df_avg.reset_index().set_index(['USAF','year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfz={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119000\n",
      "127560\n",
      "127660\n",
      "127720\n",
      "127860\n",
      "128050\n",
      "128120\n",
      "128150\n",
      "128220\n",
      "128250\n",
      "128300\n",
      "128305\n",
      "128310\n",
      "128360\n",
      "128380\n",
      "128390\n",
      "128400\n",
      "128430\n",
      "128460\n",
      "128470\n",
      "128510\n",
      "128550\n",
      "128600\n",
      "128603\n",
      "128605\n",
      "128660\n",
      "128700\n",
      "128820\n",
      "128920\n",
      "129100\n",
      "129150\n",
      "129200\n",
      "129220\n",
      "129250\n",
      "129255\n",
      "129300\n",
      "129320\n",
      "129350\n",
      "129400\n",
      "129410\n",
      "129420\n",
      "129500\n",
      "129600\n",
      "129700\n",
      "129820\n",
      "129920\n",
      "150000\n",
      "150001\n",
      "150002\n",
      "150010\n",
      "150040\n",
      "150070\n",
      "150090\n",
      "150100\n",
      "150105\n",
      "150140\n",
      "150150\n",
      "150200\n",
      "150230\n",
      "150235\n",
      "150250\n",
      "150320\n",
      "150330\n",
      "150400\n",
      "150410\n",
      "150420\n",
      "150440\n",
      "150470\n",
      "150520\n",
      "150550\n",
      "150560\n",
      "150630\n",
      "150690\n",
      "150730\n",
      "150750\n",
      "150800\n",
      "150830\n",
      "150850\n",
      "150880\n",
      "150890\n",
      "150900\n",
      "150940\n",
      "150950\n",
      "150990\n",
      "151070\n",
      "151080\n",
      "151090\n",
      "151110\n",
      "151130\n",
      "151170\n",
      "151180\n",
      "151190\n",
      "151200\n",
      "151205\n",
      "151230\n",
      "151240\n",
      "151270\n",
      "151320\n",
      "151340\n",
      "151360\n",
      "151380\n",
      "151400\n",
      "151430\n",
      "151450\n",
      "151455\n",
      "151480\n",
      "151500\n",
      "151540\n",
      "151580\n",
      "151590\n",
      "151600\n",
      "151620\n",
      "151630\n",
      "151650\n",
      "151680\n",
      "151700\n",
      "151740\n",
      "151790\n",
      "151820\n",
      "151840\n",
      "151890\n",
      "151940\n",
      "151970\n",
      "151990\n",
      "152000\n",
      "152005\n",
      "152040\n",
      "152060\n",
      "152080\n",
      "152090\n",
      "152120\n",
      "152150\n",
      "152170\n",
      "152190\n",
      "152210\n",
      "152300\n",
      "152310\n",
      "152350\n",
      "152380\n",
      "152410\n",
      "152450\n",
      "152470\n",
      "152540\n",
      "152590\n",
      "152600\n",
      "152610\n",
      "152620\n",
      "152640\n",
      "152650\n",
      "152670\n",
      "152700\n",
      "152730\n",
      "152770\n",
      "152790\n",
      "152800\n",
      "152820\n",
      "152840\n",
      "152850\n",
      "152870\n",
      "152890\n",
      "152920\n",
      "152960\n",
      "152970\n",
      "152980\n",
      "152990\n",
      "153000\n",
      "153010\n",
      "153020\n",
      "153070\n",
      "153100\n",
      "153140\n",
      "153150\n",
      "153160\n",
      "153170\n",
      "153190\n",
      "153200\n",
      "153210\n",
      "153240\n",
      "153250\n",
      "153280\n",
      "153330\n",
      "153350\n",
      "153355\n",
      "153360\n",
      "153370\n",
      "153380\n",
      "153400\n",
      "153410\n",
      "153440\n",
      "153450\n",
      "153460\n",
      "153470\n",
      "153490\n",
      "153500\n",
      "153550\n",
      "153560\n",
      "153600\n",
      "153630\n",
      "153640\n",
      "153660\n",
      "153690\n",
      "153730\n",
      "153750\n",
      "153770\n",
      "153870\n",
      "153880\n",
      "153890\n",
      "153950\n",
      "154020\n",
      "154050\n",
      "154060\n",
      "154080\n",
      "154090\n",
      "154100\n",
      "154120\n",
      "154160\n",
      "154190\n",
      "154200\n",
      "154210\n",
      "154215\n",
      "154220\n",
      "154230\n",
      "154240\n",
      "154250\n",
      "154280\n",
      "154290\n",
      "154340\n",
      "154430\n",
      "154440\n",
      "154450\n",
      "154470\n",
      "154500\n",
      "154510\n",
      "154550\n",
      "154600\n",
      "154620\n",
      "154650\n",
      "154690\n",
      "154700\n",
      "154750\n",
      "154760\n",
      "154770\n",
      "154790\n",
      "154800\n",
      "154810\n",
      "154820\n",
      "154890\n",
      "154900\n",
      "154910\n",
      "154930\n",
      "154931\n",
      "154940\n",
      "154980\n",
      "154990\n"
     ]
    }
   ],
   "source": [
    "for i in filt4.index.unique(0):\n",
    "    d=df_avg2.loc[i].loc[filt4.loc[i].index.unique()]\n",
    "    dfz[i]=d\n",
    "    d.to_csv('data/'+str(i)+'.csv')\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "arr = os.listdir('data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119000.csv\n",
      "127560.csv\n",
      "127660.csv\n",
      "127720.csv\n",
      "127860.csv\n",
      "128050.csv\n",
      "128120.csv\n",
      "128150.csv\n",
      "128220.csv\n",
      "128250.csv\n",
      "128300.csv\n",
      "128305.csv\n",
      "128310.csv\n",
      "128360.csv\n",
      "128380.csv\n",
      "128390.csv\n",
      "128400.csv\n",
      "128430.csv\n",
      "128460.csv\n",
      "128470.csv\n",
      "128510.csv\n",
      "128550.csv\n",
      "128600.csv\n",
      "128603.csv\n",
      "128605.csv\n",
      "128660.csv\n",
      "128700.csv\n",
      "128820.csv\n",
      "128920.csv\n",
      "129100.csv\n",
      "129150.csv\n",
      "129200.csv\n",
      "129220.csv\n",
      "129250.csv\n",
      "129255.csv\n",
      "129300.csv\n",
      "129320.csv\n",
      "129350.csv\n",
      "129400.csv\n",
      "129410.csv\n",
      "129420.csv\n",
      "129500.csv\n",
      "129600.csv\n",
      "129700.csv\n",
      "129820.csv\n",
      "129920.csv\n",
      "150000.csv\n",
      "150001.csv\n",
      "150002.csv\n",
      "150010.csv\n",
      "150040.csv\n",
      "150070.csv\n",
      "150090.csv\n",
      "150100.csv\n",
      "150105.csv\n",
      "150140.csv\n",
      "150150.csv\n",
      "150200.csv\n",
      "150230.csv\n",
      "150235.csv\n",
      "150250.csv\n",
      "150320.csv\n",
      "150330.csv\n",
      "150400.csv\n",
      "150410.csv\n",
      "150420.csv\n",
      "150440.csv\n",
      "150470.csv\n",
      "150520.csv\n",
      "150550.csv\n",
      "150560.csv\n",
      "150630.csv\n",
      "150690.csv\n",
      "150730.csv\n",
      "150750.csv\n",
      "150800.csv\n",
      "150830.csv\n",
      "150850.csv\n",
      "150880.csv\n",
      "150890.csv\n",
      "150900.csv\n",
      "150940.csv\n",
      "150950.csv\n",
      "150990.csv\n",
      "151070.csv\n",
      "151080.csv\n",
      "151090.csv\n",
      "151110.csv\n",
      "151130.csv\n",
      "151170.csv\n",
      "151180.csv\n",
      "151190.csv\n",
      "151200.csv\n",
      "151205.csv\n",
      "151230.csv\n",
      "151240.csv\n",
      "151270.csv\n",
      "151320.csv\n",
      "151340.csv\n",
      "151360.csv\n",
      "151380.csv\n",
      "151400.csv\n",
      "151430.csv\n",
      "151450.csv\n",
      "151455.csv\n",
      "151480.csv\n",
      "151500.csv\n",
      "151540.csv\n",
      "151580.csv\n",
      "151590.csv\n",
      "151600.csv\n",
      "151620.csv\n",
      "151630.csv\n",
      "151650.csv\n",
      "151680.csv\n",
      "151700.csv\n",
      "151740.csv\n",
      "151790.csv\n",
      "151820.csv\n",
      "151840.csv\n",
      "151890.csv\n",
      "151940.csv\n",
      "151970.csv\n",
      "151990.csv\n",
      "152000.csv\n",
      "152005.csv\n",
      "152040.csv\n",
      "152060.csv\n",
      "152080.csv\n",
      "152090.csv\n",
      "152120.csv\n",
      "152150.csv\n",
      "152170.csv\n",
      "152190.csv\n",
      "152210.csv\n",
      "152300.csv\n",
      "152310.csv\n",
      "152350.csv\n",
      "152380.csv\n",
      "152410.csv\n",
      "152450.csv\n",
      "152470.csv\n",
      "152540.csv\n",
      "152590.csv\n",
      "152600.csv\n",
      "152610.csv\n",
      "152620.csv\n",
      "152640.csv\n",
      "152650.csv\n",
      "152670.csv\n",
      "152700.csv\n",
      "152730.csv\n",
      "152770.csv\n",
      "152790.csv\n",
      "152800.csv\n",
      "152820.csv\n",
      "152840.csv\n",
      "152850.csv\n",
      "152870.csv\n",
      "152890.csv\n",
      "152920.csv\n",
      "152960.csv\n",
      "152970.csv\n",
      "152980.csv\n",
      "152990.csv\n",
      "153000.csv\n",
      "153010.csv\n",
      "153020.csv\n",
      "153070.csv\n",
      "153100.csv\n",
      "153140.csv\n",
      "153150.csv\n",
      "153160.csv\n",
      "153170.csv\n",
      "153190.csv\n",
      "153200.csv\n",
      "153210.csv\n",
      "153240.csv\n",
      "153250.csv\n",
      "153280.csv\n",
      "153330.csv\n",
      "153350.csv\n",
      "153355.csv\n",
      "153360.csv\n",
      "153370.csv\n",
      "153380.csv\n",
      "153400.csv\n",
      "153410.csv\n",
      "153440.csv\n",
      "153450.csv\n",
      "153460.csv\n",
      "153470.csv\n",
      "153490.csv\n",
      "153500.csv\n",
      "153550.csv\n",
      "153560.csv\n",
      "153600.csv\n",
      "153630.csv\n",
      "153640.csv\n",
      "153660.csv\n",
      "153690.csv\n",
      "153730.csv\n",
      "153750.csv\n",
      "153770.csv\n",
      "153870.csv\n",
      "153880.csv\n",
      "153890.csv\n",
      "153950.csv\n",
      "154020.csv\n",
      "154050.csv\n",
      "154060.csv\n",
      "154080.csv\n",
      "154090.csv\n",
      "154100.csv\n",
      "154120.csv\n",
      "154160.csv\n",
      "154190.csv\n",
      "154200.csv\n",
      "154210.csv\n",
      "154215.csv\n",
      "154220.csv\n",
      "154230.csv\n",
      "154240.csv\n",
      "154250.csv\n",
      "154280.csv\n",
      "154290.csv\n",
      "154340.csv\n",
      "154430.csv\n",
      "154440.csv\n",
      "154450.csv\n",
      "154470.csv\n",
      "154500.csv\n",
      "154510.csv\n",
      "154550.csv\n",
      "154600.csv\n",
      "154620.csv\n",
      "154650.csv\n",
      "154690.csv\n",
      "154700.csv\n",
      "154750.csv\n",
      "154760.csv\n",
      "154770.csv\n",
      "154790.csv\n",
      "154800.csv\n",
      "154810.csv\n",
      "154820.csv\n",
      "154890.csv\n",
      "154900.csv\n",
      "154910.csv\n",
      "154930.csv\n",
      "154931.csv\n",
      "154940.csv\n",
      "154980.csv\n",
      "154990.csv\n"
     ]
    }
   ],
   "source": [
    "for i in arr:\n",
    "    if i not in ['all.csv']:\n",
    "        dfz[i[:-4]]=pd.read_csv('data/'+i)\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "stationc=station.set_index(0)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "for z in dfz:\n",
    "    dfz[z]=dfz[z].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "stationx={}\n",
    "for z in dfz:\n",
    "    stationx[stationc.loc[int(z)]]={'id':z,'yrs':len(dfz[z]['year'].unique())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "dq=pd.DataFrame(stationx).T.reset_index().set_index('yrs').sort_index(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yrs</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>AUREL VLAICU</td>\n",
       "      <td>154200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>GALATI</td>\n",
       "      <td>153100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>CLUJ NAPOCA</td>\n",
       "      <td>151200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>DROBETA TURNU SEVERIN</td>\n",
       "      <td>154100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>CONSTANTA</td>\n",
       "      <td>154800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     index      id\n",
       "yrs                               \n",
       "72            AUREL VLAICU  154200\n",
       "68                  GALATI  153100\n",
       "67             CLUJ NAPOCA  151200\n",
       "67   DROBETA TURNU SEVERIN  154100\n",
       "66               CONSTANTA  154800"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dq.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "dds=[]\n",
    "indicator='temp_avg'\n",
    "for a in dq.head(500)['id'].values:\n",
    "    dw=dfz[a]\n",
    "    tmean=dw.groupby(['month','hour']).mean()[[indicator]]\n",
    "    tmean.columns=['temp_mean']\n",
    "    dw=dw.loc[1980:]\n",
    "    dw=dw.loc[:2010]\n",
    "    tmean80=dw.groupby(['month','hour']).mean()[[indicator]]\n",
    "    tmean80.columns=['temp_mean80']\n",
    "    dc=dfz[a].groupby(['year','month','hour']).mean()[[indicator]].join(tmean).join(tmean80)\n",
    "    dc['temp_delta']=dc[indicator]-dc['temp_mean']\n",
    "    dc['temp_delta80']=dc[indicator]-dc['temp_mean80']\n",
    "    dd=dc.groupby(['year']).mean()\n",
    "    dd=np.round(dd,1)\n",
    "    dd['varos']=stationc[int(a)]\n",
    "    dd['value']=1\n",
    "    dds.append(dd)\n",
    "ddb=pd.concat(dds)\n",
    "ddb.to_csv('stripes/geo.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "dgeo=ddb.reset_index().set_index('varos').join(station.set_index(2))\n",
    "dgeo[dgeo[3]=='HUNGARY'].to_csv('stripes/geotest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:38: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dds=[]\n",
    "indicator='temp_avg'\n",
    "# clean_months=[1,4,7,10]\n",
    "clean_months=[1,2,3,4,5,6,7,8,9,10,11,12]\n",
    "# clean_hours=[0,6,12,18]\n",
    "clean_hours=[0,3,6,12,15,18,21]\n",
    "# clean_hours=[6]\n",
    "clean_slice=[(i,j) for i in clean_months for j in clean_hours]\n",
    "for a in dq['id'].values:\n",
    "    dw=dfz[a].groupby(['month','hour']).mean().loc[clean_slice]\n",
    "    if dw[indicator].count()==len(clean_hours)*len(clean_months):\n",
    "        \n",
    "        dc=dfz[a].set_index(['month','hour']).loc[clean_slice].reset_index()\n",
    "        dx=dc.groupby(['year']).nunique()\n",
    "        full_data_years=dx[((dx['month']==len(clean_months))&(dx['hour']==len(clean_hours)))].index\n",
    "        tmean=dw.groupby(['month','hour']).mean()[[indicator]]\n",
    "        tmean.columns=['temp_mean']\n",
    "\n",
    "        dw=dfz[a].set_index(['month','hour']).loc[clean_slice].reset_index().set_index(['year']).loc[full_data_years].reset_index()\n",
    "        tmean_full_years=dw.groupby(['month','hour']).mean()[[indicator]]\n",
    "        tmean_full_years.columns=['temp_mean_full_years']\n",
    "\n",
    "        dc=dc.groupby(['year','month','hour']).mean()[[indicator]].loc[full_data_years].join(tmean).join(tmean_full_years)\n",
    "        dc['temp_delta']=dc[indicator]-dc['temp_mean']     \n",
    "        dc['temp_delta_full_years']=dc[indicator]-dc['temp_mean_full_years']     \n",
    "\n",
    "        if ((2018 in dw['year'].unique()) and (2010 in dw['year'].unique())):\n",
    "            tmean_last10=dw[dw['year']>2009].groupby(['month','hour']).mean()[[indicator]]\n",
    "            tmean_last10.columns=['temp_mean_last10']\n",
    "            dc=dc.join(tmean_last10)\n",
    "            dc['temp_delta_last10']=dc[indicator]-dc['temp_mean_last10']\n",
    "        \n",
    "        dd=dc.groupby(['year']).mean()\n",
    "        dd=np.round(dd,1)\n",
    "        dd['varos']=stationc[int(a)]\n",
    "        dd['value']=1\n",
    "        dds.append(dd)\n",
    "ddb=pd.concat(dds)\n",
    "dgeo=ddb.reset_index().set_index('varos').join(station.set_index(2))\n",
    "dgeo[dgeo[3]=='HUNGARY'].to_csv('stripes/hu.csv')\n",
    "dgeo[dgeo[3]=='ROMANIA'].to_csv('stripes/ro.csv')\n",
    "dgeo.to_csv('stripes/huro.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:38: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dds=[]\n",
    "indicator='temp_avg'\n",
    "clean_months=[1,5,9]\n",
    "# clean_months=[1,2,3,4,5,6,7,8,9,10,11,12]\n",
    "# clean_hours=[0,6,12,18]\n",
    "# clean_hours=[0,3,6,12,15,18,21]\n",
    "clean_hours=[6]\n",
    "clean_slice=[(i,j) for i in clean_months for j in clean_hours]\n",
    "for a in dq['id'].values:\n",
    "    dw=dfz[a].groupby(['month','hour']).mean().loc[clean_slice]\n",
    "    if dw[indicator].count()==len(clean_hours)*len(clean_months):\n",
    "        \n",
    "        dc=dfz[a].set_index(['month','hour']).loc[clean_slice].reset_index()\n",
    "        dx=dc.groupby(['year']).nunique()\n",
    "        full_data_years=dx[((dx['month']==len(clean_months))&(dx['hour']==len(clean_hours)))].index\n",
    "        tmean=dw.groupby(['month','hour']).mean()[[indicator]]\n",
    "        tmean.columns=['temp_mean']\n",
    "\n",
    "        dw=dfz[a].set_index(['month','hour']).loc[clean_slice].reset_index().set_index(['year']).loc[full_data_years].reset_index()\n",
    "        tmean_full_years=dw.groupby(['month','hour']).mean()[[indicator]]\n",
    "        tmean_full_years.columns=['temp_mean_full_years']\n",
    "\n",
    "        dc=dc.groupby(['year','month','hour']).mean()[[indicator]].loc[full_data_years].join(tmean).join(tmean_full_years)\n",
    "        dc['temp_delta']=dc[indicator]-dc['temp_mean']     \n",
    "        dc['temp_delta_full_years']=dc[indicator]-dc['temp_mean_full_years']     \n",
    "\n",
    "        if ((2018 in dw['year'].unique()) and (2010 in dw['year'].unique())):\n",
    "            tmean_last10=dw[dw['year']>2009].groupby(['month','hour']).mean()[[indicator]]\n",
    "            tmean_last10.columns=['temp_mean_last10']\n",
    "            dc=dc.join(tmean_last10)\n",
    "            dc['temp_delta_last10']=dc[indicator]-dc['temp_mean_last10']\n",
    "        \n",
    "        dd=dc.groupby(['year']).mean()\n",
    "        dd=np.round(dd,1)\n",
    "        dd['varos']=stationc[int(a)]\n",
    "        dd['value']=1\n",
    "        dds.append(dd)\n",
    "ddb=pd.concat(dds)\n",
    "dgeo=ddb.reset_index().set_index('varos').join(station.set_index(2))\n",
    "dgeo[dgeo[3]=='HUNGARY'].to_csv('stripes/hu_mini.csv')\n",
    "dgeo[dgeo[3]=='ROMANIA'].to_csv('stripes/ro_mini.csv')\n",
    "dgeo.to_csv('stripes/huro_mini.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>128820</td>\n",
       "      <td>99999</td>\n",
       "      <td>DEBRECEN</td>\n",
       "      <td>HUNGARY</td>\n",
       "      <td>47.489</td>\n",
       "      <td>21.615</td>\n",
       "      <td>110.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0      1         2        3       4       5      6\n",
       "28  128820  99999  DEBRECEN  HUNGARY  47.489  21.615  110.0"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "station[station[2]=='DEBRECEN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "namer={\"AGARD\":\"Agárd\",\n",
    "\"AUREL VLAICU\":\"Bukarest - Aurel Vlaicu\",\n",
    "\"BACAU\":\"Bákó\",\n",
    "\"BAJA\":\"Baja\",\n",
    "\"BEKESCSABA\":\"Békéscsaba\",\n",
    "\"BOBOC AIR BASE\":\"Boboc légi bázis\",\n",
    "\"BOTOSANI\":\"Botoșani\",\n",
    "\"BUDAPEST/PESTSZENTLORINC\":\"Budapest - Pestszentlőrinc\",\n",
    "\"BUZAU\":\"Buzău\",\n",
    "\"CALARASI\":\"Călărasi\",\n",
    "\"CAMPIA TURZII\":\"Aranyosgyéres\",\n",
    "\"CARANSEBES\":\"Káránszebes\",\n",
    "\"CATALOI\":\"Tulcea - Cataloi\",\n",
    "\"CEAHLAU TOACA\":\"Csalhó\",\n",
    "\"CLUJ NAPOCA\":\"Kolozsvár\",\n",
    "\"CONSTANTA\":\"Konstanca\",\n",
    "\"DEBRECEN\":\"Debrecen\",\n",
    "\"DEVA\":\"Déva\",\n",
    "\"DROBETA TURNU SEVERIN\":\"Szörényvár\",\n",
    "\"EGER\":\"Eger\",\n",
    "\"FERIHEGY\":\"Budapest - Ferihegy\",\n",
    "\"GALATI\":\"Galac\",\n",
    "\"GYOR\":\"Győr\",\n",
    "\"HENRI COANDA\":\"Bukarest - Henri Coandă\",\n",
    "\"IASI\":\"Jászvásár\",\n",
    "\"JOSVAFO\":\"Jósvafő\",\n",
    "\"KECSKEMET\":\"Kecskemét\",\n",
    "\"KEKESTETO\":\"Kékestető\",\n",
    "\"MIERCUREA CIUC\":\"Csíkszereda\",\n",
    "\"MIHAIL KOGALNICEANU\":\"Konstanca - Mihail Kogălniceanu\",\n",
    "\"MISKOLC\":\"Miskolc\",\n",
    "\"MOSONMAGYAROVAR\":\"Mosonmagyaróvár\",\n",
    "\"NAGYKANIZSA\":\"Nagykanizsa\",\n",
    "\"NYIREGYHAZA\":\"Nyíregyháza\",\n",
    "\"OCNA SUGATAG\":\"Aknasugatag\",\n",
    "\"ORADEA\":\"Nagyvárad\",\n",
    "\"PAKS\":\"Paks\",\n",
    "\"PAPA\":\"Pápa\",\n",
    "\"PECS SOUTH\":\"Pécs\",\n",
    "\"POROSZLO\":\"Poroszló\",\n",
    "\"RAMNICU VALCEA\":\"Râmnicu Vâlcea\",\n",
    "\"ROSIORII DE VEDE\":\"Roșiorii De Vede\",\n",
    "\"SARMELLEK\":\"Balaton - Sármellék\",\n",
    "\"SATU MARE\":\"Szatmár\",\n",
    "\"SIBIU\":\"Nagyszeben\",\n",
    "\"SIOFOK\":\"Siófok\",\n",
    "\"SOPRON\":\"Sopron\",\n",
    "\"STEFAN CEL MARE\":\"Suceava - Ștefan Cel Mare\",\n",
    "\"SULINA\":\"Sulina\",\n",
    "\"SZECSENY\":\"Szécsény\",\n",
    "\"SZEGED (AUT)\":\"Szeged\",\n",
    "\"SZENTGOTTHARD/FARKASFA\":\"Szentgotthárd\",\n",
    "\"SZOLNOK\":\"Szolnok\",\n",
    "\"SZOMBATHELY ARPT / VAS\":\"Szombathely\",\n",
    "\"TAT\":\"Tát\",\n",
    "\"TATA\":\"Tata\",\n",
    "\"TAUTII MAGHERAUS\":\"Nagybánya - Miszmogyorós\",\n",
    "\"TRAIAN VUIA\":\"Temesvár - Traian Vuia\",\n",
    "\"VARFU OMU\":\"Bucsecs - Omu csúcs\",\n",
    "\"VESZPREM/SZENTKIRALYSZABADJA\":\"Veszprém\",\n",
    "\"VIDRASAU\":\"Marosvásárhely - Vidrátszeg\",\n",
    "\"ZAHONY\":\"Záhony\",\n",
    "\"ZALAEGERSZEG/ANDRASHIDA\":\"Zalaegerszeg\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2143"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open('namer.json','w').write(json.dumps(namer))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
